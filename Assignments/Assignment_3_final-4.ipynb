{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18288433",
   "metadata": {
    "deletable": false
   },
   "source": [
    "\n",
    "# Assignment 3 for Course 1MS041\n",
    "Make sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be576d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37109a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Download the updated data folder from the course github website or just download directly the file [https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/smhi.csv](https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/smhi.csv) from the github website and put it inside your data folder, i.e. you want the path `data/smhi.csv`. The data was aquired from SMHI (Swedish Meteorological and Hydrological Institute) and constitutes per hour measurements of wind in the Uppsala Aut station. The data consists of windspeed and direction. Your goal is to load the data and work with it a bit. The code you produce should load the file as it is, please do not alter the file as the autograder will only have access to the original file.\n",
    "\n",
    "The file information is in Swedish so you need to use some translation service, for instance `Google translate` or ChatGPT.\n",
    "\n",
    "1. [2p] Load the file, for instance using the `csv` package. Put the wind-direction as a numpy array and the wind-speed as another numpy array.\n",
    "2. [2p] Use the wind-direction which is an angle in degrees and convert it into a point on the unit circle. Store the `x_coordinate` as one array and the `y_coordinate` as another. From these coordinates, construct the wind-velocity vector.\n",
    "3. [2p] Calculate the average wind velocity and convert it back to direction and compare it to just taking average of the wind direction as given in the data-file.\n",
    "4. [2p] The wind velocity is a $2$-dimensional random variable, calculate the empirical covariance matrix which should be a numpy array of shape (2,2).\n",
    "\n",
    "For you to wonder about, is it more likely for you to have headwind or not when going to the university in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98e2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Tid (UTC)</th>\n",
       "      <th>Vindriktning</th>\n",
       "      <th>Kvalitet</th>\n",
       "      <th>Vindhastighet</th>\n",
       "      <th>Kvalitet.1</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Tidsutsnitt:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>348</td>\n",
       "      <td>G</td>\n",
       "      <td>0.6</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data fr책n senaste fyra m책naderna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>G</td>\n",
       "      <td>0.2</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tidsperiod (fr.o.m.) = 2024-06-27 00:00:01 (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>185</td>\n",
       "      <td>G</td>\n",
       "      <td>0.1</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tidsperiod (t.o.m.) = 2024-11-04 05:00:00 (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>126</td>\n",
       "      <td>G</td>\n",
       "      <td>0.8</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samplingstid = 10 minuter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>130</td>\n",
       "      <td>G</td>\n",
       "      <td>0.7</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvalitetskoderna:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum Tid (UTC)  Vindriktning Kvalitet  Vindhastighet Kvalitet.1  \\\n",
       "0  2024-06-27  01:00:00           348        G            0.6          G   \n",
       "1  2024-06-27  02:00:00            43        G            0.2          G   \n",
       "2  2024-06-27  03:00:00           185        G            0.1          G   \n",
       "3  2024-06-27  04:00:00           126        G            0.8          G   \n",
       "4  2024-06-27  05:00:00           130        G            0.7          G   \n",
       "\n",
       "   Unnamed: 6                                      Tidsutsnitt:  \n",
       "0         NaN                  Data fr책n senaste fyra m책naderna  \n",
       "1         NaN  Tidsperiod (fr.o.m.) = 2024-06-27 00:00:01 (UTC)  \n",
       "2         NaN   Tidsperiod (t.o.m.) = 2024-11-04 05:00:00 (UTC)  \n",
       "3         NaN                         Samplingstid = 10 minuter  \n",
       "4         NaN                                 Kvalitetskoderna:  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/smhi.csv', sep=';', skiprows=11)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d555ce1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Import the data \n",
    "data = pd.read_csv('data/smhi.csv', sep=';', skiprows=11)\n",
    "# Keep only the non-empty columns\n",
    "data = data[['Datum','Tid (UTC)', 'Vindriktning', 'Kvalitet', 'Vindhastighet', 'Kvalitet.1','Tidsutsnitt:']]\n",
    "# In the dataset description it is written that some data has a good quality and some are suspicious - we need to keep only good\n",
    "# Filter for rows with \"Quality\" as 'G' (good data)\n",
    "data = data[data['Kvalitet'] == 'G']\n",
    "\n",
    "# Separate wind direction and speed data in an array\n",
    "wind_direction =  data['Vindriktning'].to_numpy(dtype=np.float64)\n",
    "wind_speed = data['Vindhastighet'].to_numpy(dtype=np.float64)\n",
    "\n",
    "problem1_wind_direction = wind_direction\n",
    "problem1_wind_speed = wind_speed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a021927",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The wind direction is given as a compass direction in degrees (0-360)\n",
    "# convert it to x and y coordinates using the standard mathematical convention\n",
    "# x^2 + y^2 = 1, y=sin(t), x=cos(t)\n",
    "\n",
    "# Convert degrees to radians\n",
    "ang_rad = np.radians(wind_direction)\n",
    "\n",
    "problem1_wind_direction_x_coordinate = np.cos(ang_rad)\n",
    "problem1_wind_direction_y_coordinate = np.sin(ang_rad)\n",
    "\n",
    "# Wind-velocity vectors\n",
    "wind_velocity_x = problem1_wind_direction_x_coordinate * wind_speed\n",
    "wind_velocity_y = problem1_wind_direction_y_coordinate * wind_speed\n",
    "\n",
    "problem1_wind_velocity_x_coordinate = wind_velocity_x\n",
    "problem1_wind_velocity_y_coordinate = wind_velocity_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5eaa4a4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Put the average wind velocity x and y coordinates here in these variables\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(wind_velocity_x)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(wind_velocity_y)\n",
    "\n",
    "# First calculate the angle of the average wind velocity vector in degrees\n",
    "# Compute the angle (in degrees) of the average vector\n",
    "problem1_average_wind_velocity_angle_degrees = np.degrees(np.arctan2(problem1_average_wind_velocity_y_coordinate, problem1_average_wind_velocity_x_coordinate)) % 360\n",
    "# Then calculate the average angle of the wind direction in degrees (using the wind direction in the data)\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)  \n",
    "\n",
    "# 7.09101 is the difference which is too big --> suggest that they are not equal\n",
    "diff = np.abs(problem1_average_wind_velocity_angle_degrees - problem1_average_wind_direction_angle_degrees)\n",
    "#diff\n",
    "\n",
    "# Finally, are they the same? Answer as a boolean value (True or False)\n",
    "problem1_same_angle = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30621c34",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "wind_velocity_cov =  np.vstack((problem1_wind_velocity_x_coordinate, problem1_wind_velocity_y_coordinate))\n",
    "covariance_matrix = np.cov(wind_velocity_cov)\n",
    "#covariance_matrix\n",
    "problem1_wind_velocity_covariance_matrix = covariance_matrix\n",
    "# the shapes are as expected now\n",
    "# print(wind_velocity_cov.shape)  # shape (3061, 2)\n",
    "# print(problem1_wind_velocity_covariance_matrix.shape) # shape (2,2)\n",
    "# covariance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e56743",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238a00",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "For this problem you will need the [pandas](https://pandas.pydata.org/) package and the [sklearn](https://scikit-learn.org/stable/) package. Inside the `data` folder from the course website you will find a file called `indoor_train.csv`, this file includes a bunch of positions in (X,Y,Z) and also a location number. The idea is to assign a room number (Location) to the coordinates (X,Y,Z).\n",
    "\n",
    "1. [2p] Take the data in the file `indoor_train.csv` and load it using pandas into a dataframe `df_train`\n",
    "2. [3p] From this dataframe `df_train`, create two numpy arrays, one `Xtrain` and `Ytrain`, they should have sizes `(1154,3)` and `(1154,)` respectively. Their `dtype` should be `float64` and `int64` respectively.\n",
    "3. [3p] Train a Support Vector Classifier, `sklearn.svc.SVC`, on `Xtrain, Ytrain` with `kernel='linear'` and name the trained model `svc_train`.\n",
    "\n",
    "To mimic how [kaggle](https://www.kaggle.com/) works, the Autograder has access to a hidden test-set and will test your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13a0482",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('data/indoor_train.csv')\n",
    "\n",
    "df_train = df_train\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da145026",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Rename the variables \n",
    "df_train.rename(columns={'Position X': 'X', ' Position Y': 'Y', 'Position Z': 'Z', 'Location': 'Location'}, inplace=True)\n",
    "\n",
    "# Split the data into dependent and independent vars\n",
    "Xtrain = df_train[['X', 'Y', 'Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Check if dimension size is correct \n",
    "# Xtrain.shape\n",
    "# Ytrain.shape\n",
    "\n",
    "Xtrain = Xtrain\n",
    "Ytrain = Ytrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0663333",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the SVC model\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n",
    "svc_train = svc_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb489b2",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7f987",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem3_X` which has shape **(n_texts,3)** where each feature in `problem3_X` corresponds to $X_1,X_2,X_3$ from above, `problem3_Y` which has shape **(n_texts,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [2p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [2p] Train the model `problem3_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem3_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem3_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem3_calibrator`. Recall that calibration error is the following for a fixed function $f$\n",
    "$$\n",
    "    \\sqrt{\\mathbb{E}[|\\mathbb{E}[Y \\mid f(X)] - f(X)|^2]}.\n",
    "$$\n",
    "\n",
    "4. [2p] Use the trained model `problem3_ps` and the calibrator `problem3_calibrator` to make final predictions on the testing data, store the prediction in `problem3_final_predictions`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0bc703",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2228, 3) (1114, 3) (2230, 3) (2228,) (1114,) (2230,)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data \n",
    "spam = pd.read_csv(\"data/spam.csv\",encoding=\"latin1\")\n",
    "spam = spam[['v1','v2']]\n",
    "\n",
    "# Use the words free, prize and win to create binary variables X1, X2, X3 respectively that show if each word is present in every line of emails.\n",
    "spam[\"X1\"] = spam[\"v2\"].str.contains(r\"\\bfree\\b\", case=False, na=False).astype(int)\n",
    "spam[\"X2\"] = spam[\"v2\"].str.contains(r\"\\bprize\\b\", case=False, na=False).astype(int)\n",
    "spam[\"X3\"] = spam[\"v2\"].str.contains(r\"\\bwin\\b\", case=False, na=False).astype(int)\n",
    "\n",
    "# Independent variables \n",
    "problem3_X = spam[[\"X1\", \"X2\", \"X3\"]].to_numpy() \n",
    "\n",
    "# Dependent variable (spam/not spam)\n",
    "spam[\"spam\"] = spam[\"v1\"].map({\"spam\": 1, \"ham\": 0}).astype(int)\n",
    "problem3_Y = spam[\"spam\"].to_numpy()  \n",
    "\n",
    "# 40% train and 60% combined - calibration and test\n",
    "problem3_X_train, X_comb, problem3_Y_train, Y_comb = train_test_split(problem3_X, problem3_Y, test_size=0.6, stratify=problem3_Y, random_state=10)\n",
    "\n",
    "# 20% calibration and 40% test\n",
    "problem3_X_calib, problem3_X_test, problem3_Y_calib, problem3_Y_test = train_test_split(X_comb, Y_comb, test_size=0.6666666666667, stratify=Y_comb, random_state=10)\n",
    "\n",
    "problem3_X_train = problem3_X_train\n",
    "problem3_X_calib = problem3_X_calib\n",
    "problem3_X_test = problem3_X_test\n",
    "\n",
    "problem3_Y_train = problem3_Y_train\n",
    "problem3_Y_calib = problem3_Y_calib\n",
    "problem3_Y_test = problem3_Y_test\n",
    "\n",
    "# Check if the variables were created correctly\n",
    "\n",
    "# spam.head()\n",
    "# Check the shapes of the splits\n",
    "size_y_train = problem3_Y_train.shape[0]\n",
    "size_y_calib = problem3_Y_calib.shape[0]\n",
    "size_y_test = problem3_Y_test.shape[0]\n",
    "\n",
    "total = size_y_train + size_y_calib + size_y_test\n",
    "train_perc = size_y_train/total\n",
    "calib_perc = size_y_calib/total\n",
    "test_perc = size_y_test/total\n",
    "#print(train_perc)\n",
    "#print(calib_perc)\n",
    "#print(test_perc)\n",
    "print(problem3_X_train.shape,problem3_X_calib.shape,problem3_X_test.shape,problem3_Y_train.shape,problem3_Y_calib.shape,problem3_Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f2e1f",
   "metadata": {},
   "source": [
    "$$ \\text{Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right] $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522b4096",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        beta0 = coeffs[0]\n",
    "        beta = coeffs[1:]\n",
    "        logit = beta0 + np.dot(X, beta)\n",
    "        prob = 1 / (1 + np.exp(-logit))\n",
    "        loss = -np.mean(Y * np.log(prob) + (1 - Y) * np.log(1 - prob))\n",
    "        return loss\n",
    "    def fit(self, X, Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "        \n",
    "        # Define the optimization objective (loss function) to minimize\n",
    "        # The 'loss' method of the class is called, which calculates the loss for given coefficients\n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)  # Loss function to optimize\n",
    "\n",
    "        # Initialize coefficients with zeros (starting point for optimization)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1] + 1)  # One extra for the intercept term\n",
    "\n",
    "        # Use scipy's minimize function to optimize the loss function and find the best coefficients\n",
    "        # The 'cg' method is used here for optimization (Conjugate Gradient)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments, method='cg')\n",
    "\n",
    "        # Extract the optimized coefficients (including the intercept)\n",
    "        self.coeffs = self.result.x  # Save the optimized coefficients\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Use the trained model (i.e., the learned coefficients) to predict new Y values for input X\n",
    "        if (self.coeffs is not None):\n",
    "            # Define the logistic function (sigmoid) for probability prediction\n",
    "            G = lambda x: np.exp(x) / (1 + np.exp(x))  # Logistic (sigmoid) function\n",
    "\n",
    "            # Predict using the model coefficients:\n",
    "            # np.dot(X, self.coeffs[1:]) computes the dot product between X and coefficients (excluding intercept)\n",
    "            # self.coeffs[0] adds the intercept term\n",
    "            # The logistic function transforms the result into a probability\n",
    "            # np.round(..., 10) rounds the probability to 1 decimal place for calibration\n",
    "            return np.round(10 * G(np.dot(X, self.coeffs[1:]) + self.coeffs[0])) / 10  # Calibrated rounding of the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97f059a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the custom model, for spam prediction\n",
    "problem3_ps = ProportionalSpam()\n",
    "\n",
    "# Fit the custom model to the training data (X_train for features, Y_train for labels)\n",
    "problem3_ps.fit(problem3_X_train, problem3_Y_train)\n",
    "\n",
    "# Use the fitted model to generate predictions for the calibration data (X_calib)\n",
    "# The predictions are reshaped into a column vector to match the expected input format for the next step\n",
    "problem3_X_pred = problem3_ps.predict(problem3_X_calib).reshape(-1, 1)\n",
    "\n",
    "# Initialize the DecisionTreeRegressor, which will be used for calibrating the initial model's predictions\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the decision tree regressor to the predictions from the ProportionalSpam model (X_pred) and the actual calibration values (Y_calib)\n",
    "# The decision tree learns the relationship between the predicted values and the true target labels to calibrate the output\n",
    "problem3_calibrator.fit(problem3_X_pred, problem3_Y_calib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f477aa",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Use the fitted ProportionalSpam model to make predictions on the test data (X_test)\n",
    "# The predictions are reshaped into a column vector to match the expected input format for the next step\n",
    "prob_test_dt = problem3_ps.predict(problem3_X_test).reshape(-1, 1)\n",
    "\n",
    "# Use the trained decision tree regressor to adjust the predictions from the ProportionalSpam model\n",
    "# The decision tree has learned how to calibrate these predictions based on the calibration data\n",
    "problem3_final_predictions = problem3_calibrator.predict(prob_test_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197c659",
   "metadata": {},
   "source": [
    "\n",
    "Calibration ensures that the predicted probabilities from a model are aligned with the true probabilities. Here are the steps:\n",
    "\n",
    "\n",
    "1. **Split the Data**:\n",
    "   - Divide the training data into two parts:\n",
    "     - **Training set**: Used to train the initial model.\n",
    "     - **Calibration set**: Used to train the calibration model.\n",
    "\n",
    "2. **Train the Initial Model**:\n",
    "   - Train the base model (e.g., logistic regression, neural network, etc.) on the training set.\n",
    "   - This model produces uncalibrated probability estimates.\n",
    "\n",
    "3. **Obtain Predictions on the Calibration Set**:\n",
    "   - Use the trained base model to predict probabilities for the calibration set.\n",
    "\n",
    "4. **Train a Calibration Model**:\n",
    "   - Fit a simple model (calibration model) to adjust the uncalibrated probabilities. Common calibration methods include:\n",
    "     - **Platt Scaling**: Fits a logistic regression to map the uncalibrated probabilities to calibrated ones.\n",
    "     - **Isotonic Regression**: A non-parametric method that fits a piecewise constant function.\n",
    "     - **Decision Trees**: In the given example, a decision tree regressor was trained to calibrate predictions.\n",
    "\n",
    "5. **Evaluate Calibration**:\n",
    "   - Use metrics like the **Brier score** or **reliability diagrams** to evaluate the calibrated probabilities.\n",
    "   - Check if the calibrated probabilities align well with observed outcomes.\n",
    "\n",
    "6. **Calibrate Predictions on the Test Set**:\n",
    "   - Use the calibration model to adjust the test predictions generated by the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239bda0",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 3, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abcb445",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "lx_assignment_number": 3,
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
