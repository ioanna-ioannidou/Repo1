{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "header = []\n",
    "data = []\n",
    "\n",
    "with open('data/final.csv', 'r') as datafile:\n",
    "    csv_read = csv.reader(datafile)\n",
    "    #csv_read = csv.reader(datafile, delimiter=' ')  # Specify space as delimite)\n",
    "    header = next(csv_read)\n",
    "\n",
    "    data = [row for row in csv_read]\n",
    "    # Parse the data and convert each entry to a float\n",
    "    #data = [[float(value) for value in row] for row in csv_read]\n",
    "head = data[:5]\n",
    "print(head)\n",
    "data_array = np.array(data)\n",
    "num_rows, num_columns = data_array.shape\n",
    "print(num_rows)\n",
    "print(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependence & Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A): Probability of rolling a 6 = 0.16666666666666666\n",
      "P(B): Probability of flipping 'Heads' = 0.5\n",
      "P(A ∩ B): Combined probability (independence assumption) = 0.08333333333333333\n",
      "\n",
      "Simulation to verify independence:\n",
      "Simulated P(A): 0.1686\n",
      "Simulated P(B): 0.49761\n",
      "Simulated P(A ∩ B): 0.08427\n",
      "Check: P(A) * P(B) ≈ 0.083897046\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def calculate_probabilities():\n",
    "    # Probabilities of the individual events\n",
    "    P_A = 1 / 6  # Probability of rolling a 6\n",
    "    P_B = 1 / 2  # Probability of flipping \"Heads\"\n",
    "\n",
    "    # Combined probability of both events happening (independent)\n",
    "    P_A_and_B = P_A * P_B\n",
    "\n",
    "    print(f\"P(A): Probability of rolling a 6 = {P_A}\")\n",
    "    print(f\"P(B): Probability of flipping 'Heads' = {P_B}\")\n",
    "    print(f\"P(A ∩ B): Combined probability (independence assumption) = {P_A_and_B}\")\n",
    "\n",
    "    # Simulate to verify\n",
    "    print(\"\\nSimulation to verify independence:\")\n",
    "    total_trials = 100000\n",
    "    count_A = 0\n",
    "    count_B = 0\n",
    "    count_A_and_B = 0\n",
    "\n",
    "    for _ in range(total_trials):\n",
    "        die_roll = random.randint(1, 6)\n",
    "        coin_flip = random.choice([\"Heads\", \"Tails\"])\n",
    "\n",
    "        if die_roll == 6:\n",
    "            count_A += 1\n",
    "        if coin_flip == \"Heads\":\n",
    "            count_B += 1\n",
    "        if die_roll == 6 and coin_flip == \"Heads\":\n",
    "            count_A_and_B += 1\n",
    "\n",
    "    # Estimated probabilities from simulation\n",
    "    simulated_P_A = count_A / total_trials\n",
    "    simulated_P_B = count_B / total_trials\n",
    "    simulated_P_A_and_B = count_A_and_B / total_trials\n",
    "\n",
    "    print(f\"Simulated P(A): {simulated_P_A}\")\n",
    "    print(f\"Simulated P(B): {simulated_P_B}\")\n",
    "    print(f\"Simulated P(A ∩ B): {simulated_P_A_and_B}\")\n",
    "    print(f\"Check: P(A) * P(B) ≈ {simulated_P_A * simulated_P_B}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    calculate_probabilities()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint the PMF of N is p_N(k) where p_N is\n",
    "from scipy.special import binom as binomial\n",
    "p = 6/10 # probability \n",
    "p_N = lambda k: binomial(10,k)*((1-p)**(10-k))*((p)**k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def X():\n",
    "    \"\"\"Produces a single random number from DeMoivre(1/3,1/3,1/3)\"\"\"\n",
    "    return randint(0,2)\n",
    "\n",
    "def empirical_mean(n=1):\n",
    "    \"\"\"Produces the empirical mean of n experiments of the X above\"\"\"\n",
    "    Z = [X() for i in range(n)]\n",
    "    return sum(Z)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chebychev's Inequality\n",
    "Consider an i.i.d. sequence of random variables $X_1,\\ldots,X_n$ each being Bernoulli($1/2$). Then the concept of concentration is telling us that\n",
    "\n",
    "$$\n",
    "    P\\left ( \\left | \\frac{1}{n} \\sum_{i=1}^n X_i - \\mathbb{E}(X_i) \\right | > \\epsilon \\right )\n",
    "$$\n",
    "\n",
    "gets smaller as $n$ gets larger. For instance, using Chebychevs inequality we get\n",
    "\n",
    "$$\n",
    "    P\\left ( \\left | \\frac{1}{n} \\sum_{i=1}^n X_i - \\mathbb{E}(X_i) \\right | > \\epsilon \\right ) \\leq \\frac{\\mathbb{V}\\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right )}{\\epsilon^2} = \\frac{\\mathbb{V}\\left( X_0 \\right )}{\\epsilon^2 n}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chebyshev bound for P(|X - 0| >= 2 * 1): 0.00025\n"
     ]
    }
   ],
   "source": [
    "def chebyshev_bound(k, n, mean=0, std_dev=1):\n",
    "    \"\"\"\n",
    "    Computes the Chebyshev bound for a given k, n, mean, and standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "    - k: Threshold for deviation from the mean\n",
    "    - n: Number of samples\n",
    "    - mean: The mean of the distribution (default is 0)\n",
    "    - std_dev: The standard deviation of the distribution (default is 1)\n",
    "    \n",
    "    Returns:\n",
    "    - Bound: The Chebyshev bound for the probability that the deviation exceeds k.\n",
    "    \"\"\"\n",
    "    # Chebyshev's inequality: P(|X - mean| >= k * std_dev) <= 1 / k^2\n",
    "    bound = 1 / (k**2 * n)\n",
    "    return bound\n",
    "\n",
    "# Example usage:\n",
    "k = 2        # Threshold (number of standard deviations)\n",
    "n = 1000     # Number of samples\n",
    "mean = 0     # Mean of the distribution\n",
    "std_dev = 1  # Standard deviation of the distribution\n",
    "\n",
    "bound = chebyshev_bound(k, n, mean, std_dev)\n",
    "print(f\"Chebyshev bound for P(|X - {mean}| >= {k} * {std_dev}): {bound:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoeffding's Bound\n",
    "$$\n",
    "P\\left ( \\left | \\frac{1}{n} \\sum_{i=1}^n X_i - \\mathbb{E}(X_i) \\right | > \\epsilon \\right ) \\leq \\frac{\\mathbb{V}\\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right )}{\\epsilon^2} = \\frac{\\mathbb{V}\\left( X_0 \\right )}{\\epsilon^2 n}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoeffding's bound for P(|X_bar - E(X)| > 0.1): 0.00000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hoeffding_bound(epsilon, n, a, b):\n",
    "    \"\"\"\n",
    "    Computes Hoeffding's bound for the probability that the sample mean \n",
    "    deviates from the expected value by more than epsilon.\n",
    "    \n",
    "    Parameters:\n",
    "    - epsilon: The deviation threshold.\n",
    "    - n: The number of samples.\n",
    "    - a: The lower bound of the random variable.\n",
    "    - b: The upper bound of the random variable.\n",
    "    \n",
    "    Returns:\n",
    "    - The Hoeffding bound on the probability.\n",
    "    \"\"\"\n",
    "    # Hoeffding's inequality formula: 2 * exp(-2 * n * epsilon^2 / (b - a)^2)\n",
    "    bound = 2 * np.exp(-2 * n * epsilon**2 / (b - a)**2)\n",
    "    return bound\n",
    "\n",
    "# Example usage:\n",
    "epsilon = 0.1      # Threshold for deviation\n",
    "n = 1000           # Number of samples\n",
    "a = 0              # Lower bound of the random variable\n",
    "b = 1              # Upper bound of the random variable\n",
    "\n",
    "bound = hoeffding_bound(epsilon, n, a, b)\n",
    "print(f\"Hoeffding's bound for P(|X_bar - E(X)| > {epsilon}): {bound:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use concentration as a measure of confidence in the following way. Consider $X_1,\\ldots, X_n$ being i.i.d. sequence of Bernoulli($p$) for some unknown $p$. From the concept of concentration, we would expect that if we have many observations ($n$ large) we could use the empirical mean of the observations as a guess, but note that there is some variability as we saw in the above simulations. So what do we do? We use the concentration inequality to get information how far we can deviate from $p$ in the following way\n",
    "\n",
    "$$\n",
    "    P(\\bar X_n - \\mathbb{E}(\\bar X_n) \\geq \\epsilon) \\leq e^{-2n\\epsilon^2}\n",
    "$$\n",
    "\n",
    "Since $\\mathbb{E}(\\bar X_n) = p$, rearrange and get\n",
    "\n",
    "$$\n",
    "    P(p \\leq \\bar X_n - \\epsilon) \\leq e^{-2n\\epsilon^2}\n",
    "$$\n",
    "\n",
    "The complementary event thus satisfies\n",
    "\n",
    "$$\n",
    "    P(\\bar X_n - \\epsilon < p) \\geq 1-e^{-2n\\epsilon^2}\n",
    "$$\n",
    "\n",
    "We can do the same for the other side (see lecture notes) and we get\n",
    "\n",
    "$$\n",
    "    P(\\bar X_n - \\epsilon < p < \\bar X_n + \\epsilon) \\geq 1-2 e^{-2n\\epsilon^2}.\n",
    "$$\n",
    "\n",
    "If you where now asked to estimate $p$ using $n$ observations and give an interval where you with at least 95% confidence can say contains $p$, then you need to choose $\\epsilon > 0$ such that\n",
    "\n",
    "$$\n",
    "    1-2 e^{-2n\\epsilon^2} \\geq 0.95.\n",
    "$$\n",
    "\n",
    "Smaller $\\epsilon$ gives smaller intervals, so lets choose to have the smallest possible $\\epsilon$ while still obaying the inequality above, i.e. we choose $\\epsilon$ to solve\n",
    "\n",
    "$$\n",
    "    1-2 e^{-2n\\epsilon^2} = 0.95.\n",
    "$$\n",
    "\n",
    "Rearranging we and taking log and then square root we obtain\n",
    "\n",
    "$$\n",
    "    \\epsilon = \\sqrt{-\\frac{1}{2n}\\ln\\left(\\frac{1-0.95}{2}\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To estimate p with 95.0% confidence, choose epsilon = 0.04295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_epsilon(n, confidence=0.95):\n",
    "    \"\"\"\n",
    "    To estimate p with 95.0% confidence, choose epsilon = 0.02899\n",
    "\n",
    "    Computes the value of epsilon for a given number of samples n and confidence level.\n",
    "    \n",
    "    Parameters:\n",
    "    - n: The number of samples.\n",
    "    - confidence: The desired confidence level (default is 0.95).\n",
    "    \n",
    "    Returns:\n",
    "    - epsilon: The value of epsilon such that the interval [X_bar - epsilon, X_bar + epsilon] contains p with the given confidence.\n",
    "    \"\"\"\n",
    "    # Solve for epsilon based on the desired confidence level\n",
    "    epsilon = np.sqrt(-np.log((1 - confidence) / 2) / (2 * n))\n",
    "    return epsilon\n",
    "    #epsilon = np.sqrt(-1/(2*n)*np.log((1-0.95)/2))\n",
    "\n",
    "# Example usage:\n",
    "n = 1000  # Number of observations\n",
    "confidence = 0.95  # Desired confidence level\n",
    "\n",
    "epsilon = compute_epsilon(n, confidence)\n",
    "print(f\"To estimate p with {confidence*100}% confidence, choose epsilon = {epsilon:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bennett's Inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bennett's inequality bound for deviation > 0.1: 0.99501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bennetts_inequality(sum_of_means, n, a, b, epsilon):\n",
    "    \"\"\"\n",
    "    Computes Bennett's inequality for the probability that the sum of independent random variables\n",
    "    deviates from its expected value by more than epsilon.\n",
    "    \n",
    "    Parameters:\n",
    "    - sum_of_means: The sum of the expected values of the individual random variables.\n",
    "    - n: The number of variables.\n",
    "    - a: The lower bound of the random variables.\n",
    "    - b: The upper bound of the random variables.\n",
    "    - epsilon: The deviation threshold.\n",
    "    \n",
    "    Returns:\n",
    "    - The probability bound from Bennett's inequality.\n",
    "    \"\"\"\n",
    "    # Compute the Bennett's inequality bound\n",
    "    variance_sum = n * (b - a)**2\n",
    "    bound = np.exp(- (n * epsilon**2) / (2 * variance_sum))\n",
    "    \n",
    "    return bound\n",
    "\n",
    "# Example \n",
    "sum_of_means = 0  # The sum of the expected values of the random variables (E[X_i] for each i)\n",
    "n = 1000          # Number of independent random variables\n",
    "a = 0             # Lower bound of the random variables\n",
    "b = 1             # Upper bound of the random variables\n",
    "epsilon = 0.1     # Threshold deviation\n",
    "\n",
    "probability_bound = bennetts_inequality(sum_of_means, n, a, b, epsilon)\n",
    "print(f\"Bennett's inequality bound for deviation > {epsilon}: {probability_bound:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bennett_epsilon(n,b,sigma,alpha):\n",
    "    import scipy.optimize as so\n",
    "    h = lambda u: (1+u)*np.log(1+u)-u\n",
    "    f = lambda epsilon: np.exp(-n*sigma**2/b**2*h(b*epsilon/sigma**2))-alpha/2\n",
    "    ans = so.fsolve(f,0.002)\n",
    "    epsilon = np.abs(ans[0])\n",
    "    print(\"Numerical error\", f(epsilon))\n",
    "    return epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plus_m = len(X)\n",
    "n = n_plus_m//2\n",
    "m = n_plus_m-n\n",
    "X_train = X[0:n,:]\n",
    "Y_train = Y[0:n]\n",
    "X_test = X[n:n+m,:]\n",
    "Y_test = Y[n:n+m]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
