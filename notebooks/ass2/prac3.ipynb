{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "1"
   },
   "source": [
    "\n",
    "Using the steps in the Sample Exam Problem 1 with Solution in notebook `09.ipynb`, derive the maximum likelihood estimate for $n$ IID samples from a random variable with the following probability density function:\n",
    "$$\n",
    "f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x), \\qquad \\text{ where, } \\lambda>0, x > 0\n",
    "$$\n",
    "\n",
    "You can solve the MLe by hand (using pencil paper or using key-strokes). Present your solution as the return value of a function called `def MLeForAssignment3Problem1(x)`, where `x` is a list of $n$ input data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "1"
   },
   "outputs": [],
   "source": [
    "# do not change the name of the function, just replace XXX with the appropriate expressions for the MLe\n",
    "def MLeForAssignment3Problem1(x):\n",
    "    '''This function computes the MLE for lambda based on the given data x, which is a list of n samples.'''\n",
    "    n = len(x)  # Number of samples\n",
    "    sum_x = sum(x)  # Sum of the data points\n",
    "    lambda_hat = 5 * n / sum_x  # Maximum likelihood estimate for lambda\n",
    "    return lambda_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Joshua Fenemore collected data in 2007 on waiting times at the Orbiter bus-stop close to University of Canterbury, Christchurch, New Zealand.\n",
    "The sampled waiting times at the bus-stop, i.e., the inter-arrival time between consecutive buses, were recored in units of nearest minute and are given in the list `sampleWaitingTimes` below.\n",
    "\n",
    "Your **task** is to assume that the inter-arrival time between Orbiter buses is independent and identically distributed according to $Exponential(\\lambda)$ random variable and write a generic function:\n",
    "\n",
    "- called `mleOfExponetialLambdaRVFromIIDSamples(samples)`,\n",
    "- where `samples` is a `list` of  data points assumed to be drawn from IID  $Exponential(\\lambda)$ random variable,\n",
    "- such that, the function returns the maximum likelihood estimate or MLe $\\widehat{\\lambda}_n$ of the unknown rate parameter $\\lambda$ \n",
    "- finally get the MLe for Joshua's data by calling your function on his samples as follows:\n",
    "  - `mleOfRateParameterForOrbiterWaitingTimes = mleOfExponetialLambdaRVFromIIDSamples(sampleWaitingTimes)`\n",
    "\n",
    "(NOTE: The MLe for this model was already derived \"above\", i.e., in `09.ipynb`, so you can directly use this expression to complete your task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "2"
   },
   "outputs": [],
   "source": [
    "# do not change the sampled data-points in sampleWaitingTimes\n",
    "sampleWaitingTimes=[8,3,7,18,18,3,7,9,9,25,0,0,25,6,10,0,10,8,16,9,1,5,16,6,4,1,3,21,0,28,3,8,6,6,11,\\\n",
    "                    8,10,15,0,8,7,11,10,9,12,13,8,10,11,8,7,11,5,9,11,14,13,5,8,9,12,10,13,6,11,13,0,\\\n",
    "                    0,11,1,9,5,14,16,2,10,21,1,14,2,10,24,6,1,14,14,0,14,4,11,15,0,10,2,13,2,22,10,5,\\\n",
    "                    6,13,1,13,10,11,4,7,9,12,8,16,15,14,5,10,12,9,8,0,5,13,13,6,8,4,13,15,7,11,6,23,1]\n",
    "\n",
    "def mleOfExponetialLambdaRVFromIIDSamples(samples):\n",
    "    '''This function computes the MLE of the rate parameter lambda for an exponential distribution from IID samples.'''\n",
    "    n = len(samples)  # Number of samples\n",
    "    sample_mean = sum(samples) / n  # Sample mean\n",
    "    lambda_hat = 1 / sample_mean  # MLE for lambda\n",
    "    return lambda_hat\n",
    "\n",
    "# You should not change anything in the line below - 1 POINT\n",
    "mleOfRateParameterForOrbiterWaitingTimes = mleOfExponetialLambdaRVFromIIDSamples(sampleWaitingTimes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Use Bounded 1D Optimisation to find the maximum likelihood estimate for the IID $Bernoulli(\\theta)$ experiment using data in the array `dataSamples` below.\n",
    "\n",
    "HINT: First, Study the Solution to the **Sample Exam Problem 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Solution found.\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 11.754073319491123\n",
       "       x: 0.5294118218491145\n",
       "     nit: 9\n",
       "    nfev: 9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "# do not change next line - dataSamplesCoinToss is the sampled data-points\n",
    "dataSamplesCoinToss= np.array([0,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0])\n",
    "\n",
    "# finding MLE for IID Bernoulli(theta) RV\n",
    "# do not Chnage the name of the next function - just replace XXX\n",
    "# Negative log-likelihood function for Bernoulli distribution\n",
    "def negLogLklOBernoulliIIDSamples(paramLam):\n",
    "    '''Negative log-likelihood function for IID Bernoulli samples'''\n",
    "    n = len(dataSamplesCoinToss)  # Number of samples\n",
    "    sum_x = np.sum(dataSamplesCoinToss)  # Sum of all samples (number of 1's)\n",
    "    # Negative log-likelihood expression for Bernoulli distribution\n",
    "    neg_log_likelihood = - (sum_x * np.log(paramLam) + (n - sum_x) * np.log(1 - paramLam))\n",
    "    return neg_log_likelihood\n",
    "\n",
    "theta_initial=0.5\n",
    "\n",
    "# do NOT change the next two lines\n",
    "boundedBernoulliResult = optimize.minimize_scalar(negLogLklOBernoulliIIDSamples, theta_initial, \\\n",
    "                                                  bounds=(0.001, 0.99), method='bounded')\n",
    "boundedBernoulliResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "3"
   },
   "source": [
    "\n",
    "Obtain the 95% CI based on the asymptotic normality of the MLE for the mean paramater $\\lambda$ based on $n$ IID $Poisson(\\lambda^*)$ trials.\n",
    "\n",
    "Recall that a random variable $X \\sim Poisson(\\lambda)$ if its probability mass function is:\n",
    "\n",
    "$$\n",
    "f(x; \\lambda) = \\exp{(-\\lambda)} \\frac{\\lambda^x}{x!}, \\quad \\lambda > 0, \\quad x \\in \\{0,1,2,\\ldots\\}\n",
    "$$\n",
    "\n",
    "The MLe $\\widehat{\\lambda}_n = \\overline{x}_n$, the sample mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI for lambda based on IID Poisson(lambda) data in samplePoissonCounts = \n",
      "3.638876042658652 7.694457290674682\n"
     ]
    }
   ],
   "source": [
    "# Only replace the XXX below, do not change the function naemes or parameters\n",
    "import numpy as np\n",
    "samplePoissonCounts = np.array([0,5,11,5,6,8,9,0,1,14,2,4,4,11,2,12,10,5,6,1,7,9,8,0,5,7,11,6,0,1])\n",
    "\n",
    "def Assignment3Problem5(poissonSamples):\n",
    "    '''return the 95% confidence interval as a 2-tuple for the unknown parameter lambda* \n",
    "    from n IID Poisson(lambda*) trials in the input numpy array called samplePoissonCounts'''\n",
    "    \n",
    "    n = len(poissonSamples)  # Number of samples\n",
    "    sample_mean = np.mean(poissonSamples)  # Sample mean (MLE for lambda^*)\n",
    "    \n",
    "    # Calculate the standard error (SE) for the sample mean\n",
    "    standard_error = sample_mean / np.sqrt(n)\n",
    "    \n",
    "    # 95% confidence interval based on the asymptotic normality of the MLE\n",
    "    lower95CI = sample_mean - 1.96 * standard_error\n",
    "    upper95CI = sample_mean + 1.96 * standard_error\n",
    "    \n",
    "    return (lower95CI, upper95CI)\n",
    "\n",
    "# do NOT change anything below\n",
    "lowerCISampleExamProblem5,upperCISampleExamProblem5 = Assignment3Problem5(samplePoissonCounts)\n",
    "print (\"The 95% CI for lambda based on IID Poisson(lambda) data in samplePoissonCounts = \")\n",
    "print (lowerCISampleExamProblem5,upperCISampleExamProblem5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "3"
   },
   "source": [
    "\n",
    "For the Orbiter waiting time problem, assuming IID trials as follows: \n",
    "\n",
    "$$\\displaystyle{X_1,X_2,\\ldots,X_{n} \\overset{IID}{\\sim} Exponential(\\lambda^*)}$$\n",
    "\n",
    "Your task is to perform a Wald Test of size $\\alpha=0.05$ to try to reject the null hypothesis that the waiting time at the Orbiter bus-stop, i.e., the inter-arrival time between buses, is exactly $10$ minutes:\n",
    "\n",
    "$$\\displaystyle{H_0: \\lambda^*=\\lambda_0 \\quad \\text{ versus } \\quad H_1: \\lambda^* \\neq \\lambda_0, \\qquad \\text{ with }\\lambda_0=0.1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE lambdaHat =  9.075757575757576\n",
      "Null value of lambda under H0 =  0.1\n",
      "Estimated standard error =  0.7899433024050228\n",
      "Wald statistic =  11.362533929245838\n",
      "We reject the null hypothesis that lambda0=0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data: Waiting times for the Orbiter bus-stop\n",
    "sampleWaitingTimes = np.array([8,3,7,18,18,3,7,9,9,25,0,0,25,6,10,0,10,8,16,9,1,5,16,6,4,1,3,21,0,28,3,8,6,6,11,\n",
    "                               8,10,15,0,8,7,11,10,9,12,13,8,10,11,8,7,11,5,9,11,14,13,5,8,9,12,10,13,6,11,13,0,\n",
    "                               0,11,1,9,5,14,16,2,10,21,1,14,2,10,24,6,1,14,14,0,14,4,11,15,0,10,2,13,2,22,10,5,\n",
    "                               6,13,1,13,10,11,4,7,9,12,8,16,15,14,5,10,12,9,8,0,5,13,13,6,8,4,13,15,7,11,6,23,1])\n",
    "\n",
    "# Calculate the MLE lambdaHat (sample mean)\n",
    "lambdaHat = np.mean(sampleWaitingTimes)\n",
    "print(\"MLE lambdaHat = \", lambdaHat)\n",
    "\n",
    "# Set the null hypothesis value of lambda (lambda_0)\n",
    "NullLambda = 0.1\n",
    "print(\"Null value of lambda under H0 = \", NullLambda)\n",
    "\n",
    "# Calculate the estimated standard error for lambdaHat\n",
    "n = len(sampleWaitingTimes)  # Number of samples\n",
    "seLambda = lambdaHat / np.sqrt(n)\n",
    "print(\"Estimated standard error = \", seLambda)\n",
    "\n",
    "# Calculate the Wald statistic\n",
    "W = (lambdaHat - NullLambda) / seLambda\n",
    "print(\"Wald statistic = \", W)\n",
    "\n",
    "# Conduct the size alpha = 0.05 Wald test\n",
    "rejectNullAssignment3Problem6 = abs(W) > 1.96  # Critical value for alpha = 0.05 (two-tailed test)\n",
    "if rejectNullAssignment3Problem6:\n",
    "    print(\"We reject the null hypothesis that lambda0=0.1\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis that lambda0=0.1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Repeat the **three steps to perform a bootstrap** above as done in **Median of inter-EQ Time** example (notebook `11.ipynb`) to find the plug-in estimate and 95% CI for the *99-th Percentile of the inter-EQ time in minutes*.\n",
    "\n",
    "HINT: Median is the $50$-th Percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def getLonLatMagDepTimes(NZEQCsvFileName):\n",
    "    '''returns longitude, latitude, magnitude, depth and the origin time as unix time\n",
    "    for each observed earthquake in the csv filr named NZEQCsvFileName'''\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    from dateutil.parser import parse\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(NZEQCsvFileName) as f:\n",
    "        reader = f.read() \n",
    "        dataList = reader.split('\\n')\n",
    "        \n",
    "    myDataAccumulatorList =[]\n",
    "    for data in dataList[1:-1]:\n",
    "        dataRow = data.split(',')\n",
    "        myTimeString = dataRow[2] # origintime\n",
    "        # let's also grab longitude, latitude, magnitude, depth\n",
    "        myDataString = [dataRow[4],dataRow[5],dataRow[6],dataRow[7]]\n",
    "        try: \n",
    "            myTypedTime = time.mktime(parse(myTimeString).timetuple())\n",
    "            myFloatData = [float(x) for x in myDataString]\n",
    "            myFloatData.append(myTypedTime) # append the processed timestamp\n",
    "            myDataAccumulatorList.append(myFloatData)\n",
    "        except TypeError as e: # error handling for type incompatibilities\n",
    "            print ('Error:  Error is ', e)\n",
    "    #return np.array(myDataAccumulatorList)\n",
    "    return myDataAccumulatorList\n",
    "\n",
    "myProcessedList = getLonLatMagDepTimes('data/earthquakes.csv')\n",
    "\n",
    "def interQuakeTimes(quakeTimes):\n",
    "    '''Return a list inter-earthquake times in seconds from earthquake origin times\n",
    "    Date and time elements are expected to be in the 5th column of the array\n",
    "    Return a list of inter-quake times in seconds. NEEDS sorted quakeTimes Data'''\n",
    "    import numpy as np\n",
    "    retList = []\n",
    "    if len(quakeTimes) > 1:\n",
    "        retList = [quakeTimes[i]-quakeTimes[i-1] for i in range(1,len(quakeTimes))]\n",
    "    #return np.array(retList)\n",
    "    return retList\n",
    "\n",
    "def makeBootstrappedConfidenceIntervalOfStatisticT(dataset, statT, alpha, B=100):\n",
    "    '''make a bootstrapped 1-alpha confidence interval for ANY given statistic statT \n",
    "    from the dataset with B Bootstrap replications for 0 < alpha < 1, and \n",
    "    return lower CI, upper CI, bootstrapped_samples '''\n",
    "    n = len(dataset) # sample size of the original dataset\n",
    "    bootstrappedStatisticTs=[] # list to store the statistic T from each bootstrapped data\n",
    "    for b in range(B):\n",
    "        #sample indices at random between 0 and len(iQMinutes)-1 to make the bootstrapped dataset\n",
    "        randIndices=[randint(0,n-1) for i in range(n)] \n",
    "        bootstrappedDataset = dataset[randIndices] # resample with replacement from original dataset\n",
    "        bootstrappedStatisticT = statT(bootstrappedDataset)\n",
    "        bootstrappedStatisticTs.append(bootstrappedStatisticT)\n",
    "    # noe get the [2.5%, 97.5%] percentile-based CI\n",
    "    alpaAsPercentage=alpha*100.0\n",
    "    lowerBootstrap1MinusAlphaCIForStatisticT = np.percentile(bootstrappedStatisticTs,alpaAsPercentage/2)\n",
    "    upperBootstrap1MinusAlphaCIForStatisticT = np.percentile(bootstrappedStatisticTs,100-alpaAsPercentage/2)\n",
    "    return (lowerBootstrap1MinusAlphaCIForStatisticT,upperBootstrap1MinusAlphaCIForStatisticT,\\\n",
    "            np.array(bootstrappedStatisticTs))\n",
    "\n",
    "interQuakesSecs = interQuakeTimes(sorted([x[4] for x in myProcessedList]))\n",
    "iQMinutes = np.array(interQuakesSecs)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Plug-in Point Estimate of the 99th-Percentile of inter-EQ Times =  123.1196666666668\n",
      "1-alpha Bootstrapped CI for the 99th-Percentile of inter-EQ Times =  (118.35761666666697, 127.35301666666672)\n",
      "for alpha =  0.05  and bootstrap replicates =  1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# This is the required function for the 99th percentile of the dataset\n",
    "statT99thPercentile = lambda dataset: np.percentile(dataset, 99)  # The 99th percentile\n",
    "\n",
    "alpha = 0.05  # 95% confidence interval, so alpha = 0.05\n",
    "B = 1000  # Number of bootstrap samples\n",
    "\n",
    "# Plug-in estimate of the 99th percentile of inter-earthquake times\n",
    "plugInEstimateOf99thPercentile = np.percentile(iQMinutes, 99)\n",
    "\n",
    "# Bootstrap the 99th percentile\n",
    "lowerCIT99P, upperCIT99P, bootValuesT99P = \\\n",
    "    makeBootstrappedConfidenceIntervalOfStatisticT(iQMinutes, statT99thPercentile, alpha, B)\n",
    "\n",
    "print(\"The Plug-in Point Estimate of the 99th-Percentile of inter-EQ Times = \", plugInEstimateOf99thPercentile)\n",
    "print(\"1-alpha Bootstrapped CI for the 99th-Percentile of inter-EQ Times = \", (lowerCIT99P, upperCIT99P))\n",
    "print(\"for alpha = \", alpha, \" and bootstrap replicates = \", B)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "lx_assignment_number": "3",
  "lx_course_instance": "2020",
  "lx_course_name": "Introduction to Data Science: A Comp-Math-Stat Approach",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
